{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d4f514-c779-47f8-8f46-9df3647ba1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28eb4263-a5d1-41ba-9400-7c54e38507f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    image = Image.open(filename)\n",
    "    image = image.convert('RGB')\n",
    "    pixels = np.asarray(image)\n",
    "    detector = MTCNN()\n",
    "    results = detector.detect_faces(pixels)\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5a7d2b-77d2-4c5f-a3d9-0a02961f2757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 22:17:43.886065: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "face = extract_face('stroke.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74365194-57db-426e-9522-fd142aedb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = face[:,:80]\n",
    "second_half = face[:,80:]\n",
    "first_half_flip = cv2.flip(first_half,1)\n",
    "second_half_flip = cv2.flip(second_half,1)\n",
    "first_half_joined = np.hstack((first_half, first_half_flip))\n",
    "second_half_joined = np.hstack((second_half_flip,second_half))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b21afd7-f44d-44aa-a600-0cf681735737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865136d5-70e1-4435-ae79-d399638ddc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_face_expression(img):\n",
    "    model_name = \"trpakov/vit-face-expression\"\n",
    "    processor = AutoProcessor.from_pretrained(model_name)\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "    image = Image.fromarray(img)\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)[0]\n",
    "    labels = model.config.id2label\n",
    "\n",
    "    results = {labels[i]: float(probabilities[i]) for i in range(len(labels))}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366da1b-1b1b-4a27-a9e5-781d28534a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
